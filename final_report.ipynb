{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb6ba06a",
   "metadata": {},
   "source": [
    "# Финальные выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b798a5e",
   "metadata": {},
   "source": [
    "# Итоговый отчёт\r\n",
    "\r\n",
    "## 1. Цель и контекст проекта  \r\n",
    "Проект посвящён применению классических методов машинного обучения для анализа химических соединений и прогнозирования их эффективности против вируса гриппа.  \r\n",
    "Основные показатели:  \r\n",
    "- **IC50** — концентрация, подавляющая активность вируса на 50%.  \r\n",
    "- **CC50** — концентрация, вызывающая 50% токсичность для клеток.  \r\n",
    "- **SI (Selectivity Index)** — коэффициент избирательности, равный CC50/IC50.\r\n",
    "\r\n",
    "Данные предоставлены в виде Excel-файла с 998 полными записями и ~195 числовыми химическими дескрипторами.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 2. Разведочный анализ данных (EDA)  \r\n",
    "- Удалены технические и константные признаки, обработаны пропуски.  \r\n",
    "- Распределения IC50, CC50 и SI оказались сильно асимметричны; для наглядности применено логарифмическое преобразование.  \r\n",
    "- Корреляции:  \r\n",
    "  - IC50 ↔ CC50: ρ ≈ +0.62  \r\n",
    "  - IC50 ↔ SI:   ρ ≈ –0.64  \r\n",
    "  - CC50 ↔ SI:   ρ ≈ +0.53  \r\n",
    "- Ни один дескриптор не коррелирует с целями сильнее |ρ| > 0.3, что указывает на сложный, нелинейный характер зависимостей.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 3. Регрессия\r\n",
    "\r\n",
    "| Задача       | Модель     | R²      | MAE       | MSE            | Комментарий                                                                       |\r\n",
    "|--------------|------------|---------|-----------|----------------|-----------------------------------------------------------------------------------|\r\n",
    "| **IC50**     | XGBoost    | 0.468   | 158.2     | 109 876.1      | Лучший результат среди моделей; RF и LGBM близки по качеству, LinearRegression не справилась. |\r\n",
    "| **CC50**     | XGBoost    | 0.468   | 293.5     | 250 627.2      | Ансамбли деревьев объясняют ≈46% дисперсии; линейная регрессия дала R² ≪ 0.       |\r\n",
    "| **SI**       | RandomForest ≈ XGB ≈ LGBM | 0.09    | ~198      | ~1 833 900      | Все модели показали очень низкое качество (R² < 0.1); регрессия SI неэффективна.   |\r\n",
    "\r\n",
    "**Вывод:** регрессия IC50 и CC50 возможна на уровне R²≈0.45–0.50 с помощью XGBoost/LightGBM, но прямой прогноз SI нецелесообразен.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 4. Классификация\r\n",
    "\r\n",
    "### 4.1. IC50 > медианы  \r\n",
    "- **RandomForest**: Accuracy 0.740, ROC AUC 0.794  \r\n",
    "- **LightGBM**: Accuracy 0.705, ROC AUC 0.775  \r\n",
    "- **XGBoost**: Accuracy 0.710, ROC AUC 0.765  \r\n",
    "- **LogisticRegression**: Accuracy 0.700, ROC AUC 0.759  \r\n",
    "\r\n",
    "### 4.2. CC50 > медианы  \r\n",
    "- **XGBoost**: Accuracy 0.730, ROC AUC 0.800  \r\n",
    "- **LightGBM**: Accuracy 0.705, ROC AUC 0.775  \r\n",
    "- **RandomForest**: Accuracy 0.690, ROC AUC 0.722  \r\n",
    "- **LogisticRegression**: Accuracy 0.690, ROC AUC 0.689  \r\n",
    "\r\n",
    "### 4.3. SI > медианы  \r\n",
    "- **LightGBM**: Accuracy 0.635, ROC AUC 0.675  \r\n",
    "- **RandomForest**: Accuracy 0.630, ROC AUC 0.675  \r\n",
    "- **LogisticRegression**: Accuracy 0.620, ROC AUC 0.665  \r\n",
    "- **XGBoost**: Accuracy 0.610, ROC AUC 0.649  \r\n",
    "\r\n",
    "### 4.4. SI > 8  \r\n",
    "- **LightGBM**: Accuracy 0.730, F1 0.614, ROC AUC 0.724  \r\n",
    "- **RandomForest**: Accuracy 0.690, F1 0.530, ROC AUC 0.722  \r\n",
    "- **XGBoost**: Accuracy 0.705, F1 0.587, ROC AUC 0.727  \r\n",
    "- **LogisticRegression**: Accuracy 0.690, F1 0.569, ROC AUC 0.689  \r\n",
    "\r\n",
    "**Вывод:**  \r\n",
    "- Для сбалансированных задач (IC50 и CC50) и муляжного порога SI>медианы точность классификации достигает 63–74%, ROC AUC ≈0.68–0.80.  \r\n",
    "- В задаче жёсткого порога SI>8 модели достигают **Accuracy до 73%**, **ROC AUC до 0.73**; LightGBM демонстрирует лучший F1.  \r\n",
    "- Градиентный бустинг (LightGBM, XGBoost) и случайный лес — лучшие методы для всех классификационных задач.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 5. Ключевые химические дескрипторы  \r\n",
    "Анализ feature importance показал, что для всех задач наиболее информативными оказались:  \r\n",
    "- **SlogP_VSAx** (поверхностные дескрипторы, связанные с липофильностью)  \r\n",
    "- **PEOE_VSAx** (электростатические поверхности)  \r\n",
    "- **EState индексы** (электротопологические характеристики)  \r\n",
    "- **Количество ароматических колец** и **полярная площадь поверхности (TPSA)**  \r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## 6. Общий вывод и рекомендации  \r\n",
    "1. **XGBoost и LightGBM** — универсальные, надёжные решения для задач регрессии (IC50, CC50) и классификации.  \r\n",
    "2. **Прямая регрессия SI** нецелесообразна из-за низкой объясняющей способности; вместо этого лучше использовать **классификацию** по порогам.  \r\n",
    "3. Для **подборки лидов** оптимально применять модель классификации SI > 8, чтобы отобрать наиболее селективные соединения.  \r\n",
    "4. При дальнейшей работе можно добавить:  \r\n",
    "   - **Feature engineering** (создание новых дескрипторов),  \r\n",
    "   - **Ансамблирование** разных алгоритмов,  \r\n",
    "   - **Тщательный подбор гиперпараметров** (Optuna),  \r\n",
    "   - **Анализ нестандартных признаков** (метаболические/биофизические данные).  \r\n",
    "\r\n",
    "Проект демонстрирует, что классические методы ML позволяют существенно ускорить приоритизацию химических кандидатов и снизить затраты на эксперименты.  \r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
